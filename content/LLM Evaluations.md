Evaluations are the equivalent to testing, but for [[LLM]]s. Basically you put an LLM after your main generation pipeline (usually [[RAG]]) to evaluate how did it do.

There are many tools for this, but at work we usually use [DeepEval](https://docs.confident-ai.com/).

